# All Models Training & Usage Guide

## âœ… Complete Model Training & Analysis Pipeline

### Step 1: Train All Models

```bash
# Train all ML models (Classification, Anomaly, Ensemble)
python3 scripts/train_ml_models.py --train-all --logs-dir data/logs
```

**What Gets Trained:**
1. âœ… **Classification Model (XGBoost)** â†’ `classification_xgboost.pkl`
2. âœ… **Anomaly Detector (Isolation Forest)** â†’ `anomaly_detector.pkl`
3. âœ… **Ensemble Configuration** â†’ `ensemble_config.json`
4. âœ… **NLP Model Check** â†’ Verifies if sentence-transformers is available

### Step 2: Analysis Uses All Models

When you run analysis, **ALL available models are automatically used**:

```bash
python3 scripts/analyze.py --logfile data/server.log
```

**Models Used During Analysis:**
1. âœ… **Supervised Classifier (Random Forest)** - From `trained_model.pkl`
2. âœ… **Classification Model (XGBoost)** - From `classification_xgboost.pkl`
3. âœ… **Anomaly Detector (Isolation Forest)** - From `anomaly_detector.pkl`
4. âœ… **NLP Model (Sentence Transformers)** - If `sentence-transformers` installed
5. âœ… **Rule-Based Analysis** - Always active
6. âœ… **Root Cause Analysis** - Always active

## ğŸ“Š Model Usage Verification

During analysis, you'll see:
```
INFO - Using models: Classification (xgboost), Anomaly Detection, Rule-Based Analysis
INFO - Ensemble ML models found X additional potential failures
```

If NLP is available:
```
INFO - Using models: Classification (xgboost), Anomaly Detection, NLP (Sentence Transformers), Rule-Based Analysis
```

## ğŸ” Complete Analysis Pipeline

```
Log File
   â†“
[1] Rule-Based Pattern Analysis âœ… (Always Active)
   â†“
[2] Supervised Classifier âœ… (If trained_model.pkl exists)
   â†“
[3] Ensemble Detector âœ… (Combines all ML models)
    â”œâ”€ Classification Model (XGBoost) âœ… - 30% weight
    â”œâ”€ Anomaly Detector (Isolation Forest) âœ… - 30% weight
    â”œâ”€ NLP Model (Sentence Transformers) âœ… - 20% weight (if available)
    â””â”€ Rule-Based Scores âœ… - 20% weight
   â†“
[4] Root Cause Analysis âœ… (Identifies primary failures)
   â†“
Final Results with All Models' Contributions
```

## ğŸ“ Training Summary

After training, you'll see:
```
[1/3] Training Classification Model...
[2/3] Training Anomaly Detector...
[3/3] Training Ensemble Detector...
[4/4] Checking NLP Model...
âœ“ NLP Model (Sentence Transformers) is available and will be used during analysis
```

## ğŸ¯ Key Features

### Automatic Model Detection
- âœ… Automatically loads all trained models
- âœ… Uses ensemble to combine predictions
- âœ… Gracefully handles missing models
- âœ… Logs which models are being used

### Model Weights (Configurable)
From `ensemble_config.json`:
```json
{
  "ensemble_weights": {
    "classification": 0.3,  // XGBoost
    "anomaly": 0.3,         // Isolation Forest
    "nlp": 0.2,             // Sentence Transformers (if available)
    "rule_based": 0.2       // Pattern matching
  }
}
```

### Comprehensive Detection
- **Rule-Based**: Catches explicit failures, HTTP errors, timeouts
- **Supervised Learning**: Learns from training data patterns
- **Classification**: XGBoost for complex pattern recognition
- **Anomaly Detection**: Finds novel/unusual patterns
- **NLP**: Semantic similarity to known error patterns
- **Root Cause**: Identifies primary failures and cascades

## ğŸš€ Quick Start

### 1. Train All Models
```bash
python3 scripts/train_ml_models.py --train-all
```

### 2. Analyze Logs (Uses All Models)
```bash
python3 scripts/analyze.py --logfile data/server.log
```

### 3. View Results
```bash
open reports/analysis_report.html
```

## âœ… Verification Checklist

After training and analysis, verify:

- [x] Classification model trained (`classification_xgboost.pkl`)
- [x] Anomaly detector trained (`anomaly_detector.pkl`)
- [x] Ensemble config created (`ensemble_config.json`)
- [x] All models loaded during analysis
- [x] "Using models: ..." log shows all active models
- [x] Ensemble predictions combine all models
- [x] Root cause analysis identifies primary failures

## ğŸ“ˆ Model Contributions

Each model contributes to final predictions:

1. **Rule-Based (20%)**: Fast, reliable for known patterns
2. **Classification (30%)**: High accuracy for learned patterns
3. **Anomaly (30%)**: Catches novel failures
4. **NLP (20%)**: Semantic understanding of error messages

**Total: 100%** - All models work together for comprehensive detection!

## ğŸ‰ Result

**All models are trained and used automatically!**

The system ensures:
- âœ… All trained models are loaded
- âœ… All available models contribute to predictions
- âœ… Ensemble combines models with proper weights
- âœ… Root cause analysis identifies primary failures
- âœ… Comprehensive failure detection with high accuracy

